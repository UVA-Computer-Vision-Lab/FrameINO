
# Frame In-N-Out: Unbounded Controllable Image-to-Video Generation

[![Paper](https://img.shields.io/badge/arXiv-Paper-b31b1b?logo=arxiv&logoColor=white)](https://arxiv.org/abs/2505.21491)
[![Website](https://img.shields.io/badge/Project-Website-pink?logo=googlechrome&logoColor=white)](https://uva-computer-vision-lab.github.io/Frame-In-N-Out/)


We propose Frame In-N-Out, a controllable image-to-video generation framework where objects can enter or exit the scene along user-defined motion trajectories. Our method introduces a new dataset curation pattern recognition, evaluation protocol, and a motion-controllable, identity-preserving video Diffusion Transformer, to achieve Frame In and Frame Out in the cinematic domain.



## <a name="Update"></a>Update ðŸ”¥ðŸ”¥ðŸ”¥
- [x] Release the paper
- [ ] Release the model weights (Wan2.1)
- [ ] Release the Wan2.1 version of ours
- [ ] Gradio demo (with online)
- [ ] Release the Training Code
- [ ] Release the Processed Training Dataset
